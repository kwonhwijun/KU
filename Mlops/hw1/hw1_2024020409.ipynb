{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[과제1]\n",
    "[수행할 작업]\n",
    "1. [수정할 코드]들을 수정해서 제출해 주세요. \n",
    "     - sqlite3을 이용해서 데이터를 추출, 적재, 화면출력하는 함수를 갖고 있는 database.py 코드를 생성\n",
    "     - database.py를 호출해서 [수정할 코드]들을 수정 --> 코드 간소화 \n",
    "     - create_tables.py 에서 predict 테이블을 생성할때 predict 컬럼만 생성하지 말고 X컬럼들도 같이 적재할수 있도록 준비. \n",
    "     - 3.batch_run.py, run.py를 수정해서 predict테이블에 추론할 X컬럼들과 추론결과(predict)가 적재 되도록 수정.\n",
    "2. run.py에서 100건의 online추론이 진행되도록 수정해 주세요. (inference.py도 수정해야 효율화가 됨)\n",
    "    - Test 테이블에서 랜덤하게 데이터 1개 추출해서 추론한 후 predict 테이블에 적재 --> 100번 반복 --> 100개의 추론결과가 predict에 적재되도록\n",
    "    - 추론을 실행한 후 predict테이블에 X값들과 추론결과(predict)가 같이 적재되도록 수정\n",
    "3. 코드들이 완성되면, 다음의 순서로 실행했을 때 에러 없이 실행되어야 합니다. \n",
    "    - python3 1.create_tables.py\n",
    "    - python3 2.train.py\n",
    "    - python3 3.batch_run.py\n",
    "    - python3 run.py \n",
    "4. 위 3을 진행한 후 steel.db 파일의 predict 테이블을 출력하면 \n",
    "    X컬럼들과 predict컬럼이 출력되고, 행의 개수는 583+100=683개가 되어야 합니다. \n",
    "[수정할 코드]\n",
    "①. \"1.create_tables.py\"\n",
    "②. \"2.train.py\"\n",
    "③. \"3.batch_run.py\"\n",
    "④. \"run.py\" \n",
    "⑤ \"inference.py\"\n",
    "[추가로 생성할 코드]\n",
    "① \"database.py\" \n",
    "과제제출이 안되거나 질문 있으시면 메일로 연락부탁드립니다. \n",
    "파일제출형태 : 학번_과제1.zip의 형태로 파일 첨부하여 제출해주세요\n",
    "jkim9747@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run 1.create_tables_my.py\n",
    "#%run 2.train_my.py\n",
    "#%run 3.batch_run_my.py\n",
    "#%run run_my.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 1.create_tables_my.py\n",
    "import database\n",
    "from database import change_dir, data2sql, create_table, print_table\n",
    "import os\n",
    "\n",
    "change_dir()\n",
    "db_name = 'steel.db'\n",
    "train_path = \"data/train.csv\"\n",
    "test_path = \"data/test.csv\"\n",
    "\n",
    "# create train/test table into DB\n",
    "data2sql(db_path = db_name , data_path = train_path, table_name = \"train\")\n",
    "data2sql(db_path = db_name, data_path = test_path, table_name = \"test\")\n",
    "\n",
    "# create predict table\n",
    "col_name ={\"predict\" : \"TEXT\" }\n",
    "create_table(db_path = db_name, table_name = \"predict\", col_dict = col_name)\n",
    "\n",
    "# print table\n",
    "print_table(db_path = db_name, table_name='train')\n",
    "print_table(db_path = db_name, table_name='test')\n",
    "print_table(db_path = db_name, table_name='predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 2.train_my.py\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import database as db\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "db.change_dir()\n",
    "# Load data from sql\n",
    "dat = db.sql2df(db_path=\"steel.db\", table_name = \"train\")\n",
    "\n",
    "## train, test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(dat, test_size=0.3)\n",
    "train.head()\n",
    "\n",
    "## x variables preprocessing \n",
    "x_cols = ['V'+str(i) for i in range(1,28)]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "trans = StandardScaler()\n",
    "trans.fit(train[x_cols])\n",
    "train_x = trans.transform(train[x_cols])\n",
    "\n",
    "## y variables preprocessing\n",
    "train['V34'] = train['Class']-1\n",
    "train_y = [str(np.where(r==1)[0][0]) for r in train[['V'+str(i) for i in range(28,35)]].to_numpy()]\n",
    "\n",
    "## classification modeling \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "## save model and transformation \n",
    "print(\"creating model file...\")\n",
    "pkl.dump(model, open(\"model.pkl\",\"wb\"))\n",
    "print(\"creating transformation file...\")\n",
    "pkl.dump(trans, open(\"transform.pkl\",\"wb\"))\n",
    "\n",
    "## make prediction for testset\n",
    "test_x = trans.transform(test[x_cols])\n",
    "pred = model.predict(test_x)\n",
    "\n",
    "## validation for testset\n",
    "test['V34'] = test['Class']-1\n",
    "test_y = [str(np.where(r==1)[0][0]) for r in test[['V'+str(i) for i in range(28,35)]].to_numpy()]\n",
    "print(np.mean(pred==test_y))\n",
    "print(pd.crosstab(test_y, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 3.batch_run_my.py\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inference as inf\n",
    "import database as db\n",
    "\n",
    "db.change_dir()\n",
    "\n",
    "## load test dataset\n",
    "dat = db.sql2df(db_path=\"steel.db\", table_name = 'test')\n",
    "\n",
    "## make prediction for test set\n",
    "print(\"\\n\\n make prediction...\")\n",
    "pred = inf.inference(dat)\n",
    "dat[\"pred\"] = pred\n",
    "\n",
    "\n",
    "## insert prediction into predict table \n",
    "db.df2sql(df_name = dat, db_path = \"steel.db\", table_name = \"predict\") # Insert 하는 방식으로 수정해야 함\n",
    "\n",
    "## print predict table\n",
    "db.print_table(db_path=\"steel.db\",table_name = \"predict\", nrow = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load run_my.py\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import database as db\n",
    "\n",
    "db.change_dir()\n",
    "\n",
    "\n",
    "db_name = \"steel.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "c = conn.cursor()\n",
    "c.execute(\"\"\" SELECT name FROM sqlite_master WHERE type='table' \"\"\")\n",
    "print(c.fetchall())\n",
    "\n",
    "c.execute(\"\"\" SELECT count(*) FROM train \"\"\")\n",
    "print(c.fetchall())\n",
    "c.execute(\"\"\" SELECT count(*) FROM test \"\"\")\n",
    "print(c.fetchall())\n",
    "c.execute(\"\"\" SELECT count(*) FROM predict \"\"\")\n",
    "print(c.fetchall())\n",
    "\n",
    "# 100개의 온라인 추론\n",
    "# 1. test 테이블에서 랜덤하게 데이터 100개 추출\n",
    "#idx = 1\n",
    "#c.execute(\"\"\" SELECT * FROM test ORDER BY RANDOM() LIMIT 2\"\"\")\n",
    "\n",
    "import call_func as cf\n",
    "import inference as infer\n",
    "ind = np.random.randint(0,583, size=100) # 100개의 랜덤한 행 인덱스 출력\n",
    "for i in ind :\n",
    "    dat = cf.call_x_value(str(i)) # test table에서 i번째 행의 데이터 불러오기\n",
    "    pred = infer.inference(dat)[0]\n",
    "    dat[\"pred\"] = pred\n",
    "    dat.to_sql(\"predict\", conn, if_exists= \"append\", index = False)\n",
    "\n",
    "print(\"After Appending 100 online inference\")\n",
    "c.execute(\"\"\" SELECT count(*) FROM predict \"\"\")\n",
    "print(c.fetchall())\n",
    "db.print_table(\"steel.db\", \"predict\", nrow = 700)\n",
    "#print_table(db_path = db_name, table_name='predict')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
